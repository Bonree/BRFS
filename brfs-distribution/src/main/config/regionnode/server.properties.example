###############################################
#############Common config#####################
###############################################

# 机器集群名
# cluster.name = brfs

# Zookeeper地址
zookeeper.addresses = localhost:2181

# datanode服务所在的服务组
# datanode.service.group = data_group

# regionnode服务群组名
# regionnode.service.group = region_group

# 插件配置
brfs.plugins.loadList = ["brfs-http-netty"]

###############################################
##############Region Node Config###################
###############################################

# regionnode服务地址
# regionnode.httpserver.host = localhost

# regionnode服务端口
regionnode.httpserver.port = 8100

# regionnode服务的IO线程数
# regionnode.httpserver.requestHandleWorkerNum = 6

# 需要进行文件清理的文件个数
# regionnode中维护的文件数量超过此值，文件清理程序
# 才会进行文件清理
#regionnode.file.clean.count = 2

# regionnode能打开的最大文件数量
#regionnode.file.max.count = 3

# 文件可以被清理的字节下限
# 文件清理程序只会清理文件空间使用比率大于此值的文件
# regionnode.file.clean.usage.rate = 0.95

# regionnode中sr向datanode写数据的线程数
# regionnode.writer.worker.num = 16

# regionnode中sr向datanode写数据时的缓存队列
# regionnode.data.pool.capacity = 60

# 数据处理程序的空闲时间
# 每个Storage Region都会对应有一个DataEngine
# 当第一条数据到达时DataEngine才会创建，如果在最后
# 一条数据写入后，在Idle设定时长的时间里都没有数据到
# 达，则删除DataEngine
# regionnode.dataengine.idle.time = PT1H


# 写数据时regionnode缓存的blocksize,需要小于物理文件块
regionnode.block.size = 16777216

# blockpool的最大值
regionnode.block.pool.capacity = 3

# blockpool的初始值
regionnode.block.pool.init.count = 1

# 向datanode发送命令关闭文件的线程数
regionnode.file.closer.thead_num=8



###############################################
##############Storage Config###################
###############################################
# Storage中文件的有效期
# 负数为无穷期限，例如"P-1D"
# storage.data.ttl = P30D

# Storage中文件的副本数
# storage.replicate.count = 2

# Storage Region中每个文件的容量大小（字节）
# storage.file.capacity = 67108864

# 默认Storage Region中分隔文件的时间段大小;
# 文件会被按照时间存储到不同的文件夹下，每个文件夹会包含此值
# 所指定的时间间隔内的所有文件
# storage.file.patition.duration = PT1H


###############################################
##############RocksDB Config###################
###############################################
# 指定rocksdb存储自定义文件名和FID的磁盘路径，默认是${brfs.home}/rocksdb，如下三个path雷同
rocksdb.storage.path = /data/rocksdb
# rocksdb的数据备份磁盘路径
rocksdb.backup.path = /data/rocksdb_backup
# rocksdb用于接收其他节点的备份文件的恢复目录
rocksdb.restore.path = /data/rocksdb_restore
# rocksdb用于临时数据恢复的目录，恢复完成后，将数据迁移到rocksdb.storage.path
rocksdb.restore.temporary.path = /data/rocksdb_temporary
# rocksdb数据过期时间，默认100天
rocksdb.data.ttl = 8640000
# 备份文件socket传输时使用的端口
rocksdb.backup.file.transfer.port = 9696
# 备份周期，单位毫秒
rocksdb.backup.cycle = 600000
# rocksdb将数据从memtable flush到level 0的并发线程数目，默认为1
rocksdb.max.background.flush = 4
# rocksdb由低级level向更高级的level进行数据归并操作的并发线程数目，默认为1
rocksdb.max.background.compaction = 4
# 最大打开文件句柄数，默认为-1
rocksdb.max.open.files = -1
# 支持compaction的并行度，为1时表示不支持，默认为1
rocksdb.max.subcompaction = 4
# 配置LRU cache的大小，用来缓存未经过压缩的block，单位MB
rocksdb.block.cache = 1024
# 单个memtable的大小，单位MB。默认是64MB
rocksdb.write.buffer.size = 128
# 指定一个RocksDB中一个列族下memtable和immutable memtable的最大数目
rocksdb.max.write.buffer.number = 4
# 至少有2个immutable memtable后才进行flush操作
rocksdb.min.write.buffer.num.to.merge = 2
# L0达到指定个数的sstable后，触发compaction L0->L1，默认是4
rocksdb.level0.file.num.compaction.trigger = 8
# L1单个文件大小，单位MB
rocksdb.target.file.size.base = 256
# L1的总大小，L1的大小建议设置成和L0大小一致，提升L0->L1的compaction效率，单位MB
rocksdb.max.bytes.level.base = 2048
# regionnode节点之间同步rocksdb数据时，一次同步的数据条数，默认50
rocksdb.data.synchronize.count.once = 50
# 控制 compaction 和 flush 每秒总的写入量
rocksdb.rate.bytes.per.second = 10240
# 使用2M的预读
rocksdb.compaction.readhead.size = 2048

# 保存节点的本地数据的目录
local.data.path = data