###############################################
#############Common config#####################
###############################################

# 机器集群名
cluster.name = cluster_name

# Zookeeper地址
zookeeper.addresses = localhost:2181

# datanode服务所在的服务组
# datanode.service.group = data_group

# regionnode服务群组名
# regionnode.service.group = region_group

# 插件配置
brfs.plugins.loadList = ["brfs-http-netty"]

###############################################
##############Region Node Config###################
###############################################

# regionnode服务地址
# regionnode.httpserver.host = localhost

# regionnode服务端口
regionnode.httpserver.port = 8100

# regionnode服务的IO线程数
# regionnode.httpserver.requestHandleWorkerNum = 6

# 需要进行文件清理的文件个数
# regionnode中维护的文件数量超过此值，文件清理程序
# 才会进行文件清理
#regionnode.file.clean.count = 2

# regionnode能打开的最大文件数量
#regionnode.file.max.count = 3

# 文件可以被清理的字节下限
# 文件清理程序只会清理文件空间使用比率大于此值的文件
# regionnode.file.clean.usage.rate = 0.95

# regionnode中sr向datanode写数据的线程数
# regionnode.writer.worker.num = 16

# regionnode中sr向datanode写数据时的缓存队列
# regionnode.data.pool.capacity = 60

# 数据处理程序的空闲时间
# 每个Storage Region都会对应有一个DataEngine
# 当第一条数据到达时DataEngine才会创建，如果在最后
# 一条数据写入后，在Idle设定时长的时间里都没有数据到
# 达，则删除DataEngine
# regionnode.dataengine.idle.time = PT1H


# 写数据时regionnode缓存的blocksize,需要小于物理文件块
regionnode.block.size = 16777216

# blockpool的最大值
regionnode.block.pool.capacity = 3

# blockpool的初始值
regionnode.block.pool.init.count = 1

# 向datanode发送命令关闭文件的线程数
regionnode.file.closer.thead_num=8



###############################################
##############Storage Config###################
###############################################
# Storage中文件的有效期
# 负数为无穷期限，例如"P-1D"
# storage.data.ttl = P30D

# Storage中文件的副本数
# storage.replicate.count = 2

# Storage Region中每个文件的容量大小（字节）
# storage.file.capacity = 67108864

# 默认Storage Region中分隔文件的时间段大小;
# 文件会被按照时间存储到不同的文件夹下，每个文件夹会包含此值
# 所指定的时间间隔内的所有文件
# storage.file.patition.duration = PT1H

######################
#####报警邮件配置######
######################

# 邮件开关，true发送邮件，false不发送邮件 默认为不开启
# email.switch=false

# 邮箱服务地址
# email.smtp=mail.bonree.com

# 邮箱服务发送端口
# email.smtp.port=25

# 邮箱发送者
# email.send.user=redalert@bonree.com

# 邮箱发送者密码
# email.send.user.password=alert!^*90

# 是否开启ssl发送
# email.use_ssl=false

# 接收者列表，通过，分割
# email.recipient=zhucg@bonree.com

# 邮件内容标题，并非邮件主题
# email.header=BRFS集群

# 邮件默认模块
# email.model=brfs

# 公司信息
# email.company=北京博睿宏远数据科技股份有限公司 版权所有   京 ICP备 08104257 号 京公网安备 1101051190

# 版权信息
# email.copyright=Copyright ©2007-2019 All rights reserved

# 发送email线程池大小
# email.pool.size=3

# deliver的开关，false为关闭，不进行推送
# deliver.switch=false

# kafka的brokers的地址列表
# kafka.brokers=192.168.4.114:9092

# deliver推送的kafka的topic
# kafka.topic=brfs_metric

# deliver缓存大小，超过大小后，将丢弃数据
# deliver.queue.size=200000

# deliver解析字段地址
# deliver.meta.url=http://devtest.ibr.cc:20003/v1

# deliver数据源
# deliver.datasource=sdk_data_brfs

# deliver的写性能表
# deliver.table.writer=brfs_writer_metric

# deliver的读性能表
# deliver.table.reader=brfs_reader_metric

###############################################
##############RocksDB Config###################
###############################################

# rocksdb存储自定义文件名和FID的磁盘路径
rocksdb.storage.path = /tmp/rocksdb

# rocksdb的数据备份磁盘路径
rocksdb.backup.path = /tmp/rocksdb_backup

# rocksdb用于接收其他节点的备份文件的恢复目录
rocksdb.restore.path = /tmp/rocksdb_restore

# rocksdb用于临时数据恢复的目录，恢复完成后，将数据迁移到rocksdb.storage.path
rocksdb.restore.temporary.path = /tmp/rocksdb_temporary

# 备份文件socket传输时使用的端口
rocksdb.backup.file.transfer.port = 9696

# 备份周期，单位毫秒
rocksdb.backup.cycle = 600000

# rocksdb将数据从memtable flush到level 0的并发线程数目，默认为1
rocksdb.max.background.flush = 4

# rocksdb由低级level向更高级的level进行数据归并操作的并发线程数目，默认为1
rocksdb.max.background.compaction = 4

# 最大打开文件句柄数，默认为-1
rocksdb.max.open.files = -1

# 支持compaction的并行度，为1时表示不支持，默认为1
rocksdb.max.subcompaction = 4

# 配置LRU cache的大小，用来缓存未经过压缩的block，单位MB
rocksdb.block.cache = 1024

# 单个memtable的大小，单位MB。默认是64MB
rocksdb.write.buffer.size = 128

# 指定一个RocksDB中一个列族下memtable和immutable memtable的最大数目
rocksdb.max.write.buffer.number = 4

# 至少有2个immutable memtable后才进行flush操作
rocksdb.min.write.buffer.num.to.merge = 2

# L0达到指定个数的sstable后，触发compaction L0->L1，默认是4
rocksdb.level0.file.num.compaction.trigger = 8

# L1单个文件大小，单位MB
rocksdb.target.file.size.base = 256

# L1的总大小，L1的大小建议设置成和L0大小一致，提升L0->L1的compaction效率，单位MB
rocksdb.max.bytes.level.base = 2048

