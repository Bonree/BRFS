###############################################
#############Common config#####################
###############################################

# 机器集群名
# cluster.name = brfs

# Zookeeper地址
zookeeper.addresses = localhost:2181

# datanode服务所在的服务组
# datanode.service.group = data_group

# regionnode服务群组名
# regionnode.service.group = region_group

# 插件配置
brfs.plugins.loadList = ["brfs-http-netty"]

###############################################
##############Region Node Config###################
###############################################

# regionnode服务地址
# regionnode.httpserver.host = localhost

# regionnode服务端口
regionnode.httpserver.port = 8100

# regionnode服务的IO线程数
# regionnode.httpserver.requestHandleWorkerNum = 6

# 需要进行文件清理的文件个数
# regionnode中维护的文件数量超过此值，文件清理程序
# 才会进行文件清理
#regionnode.file.clean.count = 2

# regionnode能打开的最大文件数量
#regionnode.file.max.count = 3

# 文件可以被清理的字节下限
# 文件清理程序只会清理文件空间使用比率大于此值的文件
# regionnode.file.clean.usage.rate = 0.95

# regionnode中sr向datanode写数据的线程数
# regionnode.writer.worker.num = 16

# regionnode中sr向datanode写数据时的缓存队列
# regionnode.data.pool.capacity = 60

# 数据处理程序的空闲时间
# 每个Storage Region都会对应有一个DataEngine
# 当第一条数据到达时DataEngine才会创建，如果在最后
# 一条数据写入后，在Idle设定时长的时间里都没有数据到
# 达，则删除DataEngine
# regionnode.dataengine.idle.time = PT1H


# 写数据时regionnode缓存的blocksize,需要小于物理文件块
regionnode.block.size = 16777216

# blockpool的最大值
regionnode.block.pool.capacity = 3

# blockpool的初始值
regionnode.block.pool.init.count = 1

# 向datanode发送命令关闭文件的线程数
regionnode.file.closer.thead_num=8



###############################################
##############Storage Config###################
###############################################
# Storage中文件的有效期
# 负数为无穷期限，例如"P-1D"
# storage.data.ttl = P30D

# Storage中文件的副本数
# storage.replicate.count = 2

# Storage Region中每个文件的容量大小（字节）
# storage.file.capacity = 67108864

# 默认Storage Region中分隔文件的时间段大小;
# 文件会被按照时间存储到不同的文件夹下，每个文件夹会包含此值
# 所指定的时间间隔内的所有文件
# storage.file.patition.duration = PT1H


###############################################
##############RocksDB Config###################
###############################################

# rocksdb存储自定义文件名和FID的磁盘路径
# rocksdb.storage.path = /tmp/rocksdb

# rocksdb的数据备份磁盘路径
# rocksdb.backup.path = /tmp/rocksdb_backup

# rocksdb用于接收其他节点的备份文件的恢复目录
#rocksdb.restore.path = /tmp/rocksdb_restore

# rocksdb用于临时数据恢复的目录，恢复完成后，将数据迁移到rocksdb.storage.path
# rocksdb.restore.temporary.path = /tmp/rocksdb_temporary

# 备份文件socket传输时使用的端口
# rocksdb.backup.file.transfer.port = 9696

# 备份周期，单位毫秒
# rocksdb.backup.cycle = 600000

# rocksdb将数据从memtable flush到level 0的并发线程数目，默认为2
rocksdb.max.background.flush = 2

# rocksdb由低级level向更高级的level进行数据归并操作的并发线程数目，默认为2
# rocksdb.max.background.compaction = 2

# 最大打开文件句柄数，默认为-1
# rocksdb.max.open.files = -1

# 支持compaction的并行度，为1时表示不支持，默认为2
# rocksdb.max.subcompaction = 2

# 配置LRU cache的大小，用来缓存未经过压缩的block，单位MB
# rocksdb.block.cache = 512

# 单个memtable的大小，单位MB。默认是64MB
# rocksdb.write.buffer.size = 64

# 指定一个RocksDB中一个列族下memtable和immutable memtable的最大数目
# rocksdb.max.write.buffer.number = 2

# 至少有1个immutable memtable后才进行flush操作
# rocksdb.min.write.buffer.num.to.merge = 1

# L0达到指定个数的sstable后，触发compaction L0->L1，默认是4
# rocksdb.level0.file.num.compaction.trigger = 4

# L1单个文件大小，单位MB
# rocksdb.target.file.size.base = 64

# L1的总大小，L1的大小建议设置成和L0大小一致，提升L0->L1的compaction效率，单位MB
# rocksdb.max.bytes.level.base = 256

